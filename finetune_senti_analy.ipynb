{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd97d42e-3d03-45d2-9bfd-76752c6712a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import pipeline\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, TrainingArguments, Trainer\n",
    "from datetime import datetime\n",
    "# import torch\n",
    "import json\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15cdfb5a-a159-4548-909f-522fa467a741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"Llama-3.1-8B-Instruct\"\n",
    "model_name = \"Llama-3.3-70B-Instruct\"\n",
    "\n",
    "model_path = os.path.join(\"./pretrained_llms\", model_name)\n",
    "data_path = \"./data\"\n",
    "data_name = \"mteb/tweet_sentiment_extraction\"\n",
    "cache_dir = \"./cache\"\n",
    "output_dir=\"./results\"\n",
    "\n",
    "dataset = load_dataset(data_name, cache_dir=data_path)\n",
    "# dataset = load_dataset(data_name, cache_dir=data_path, split='train[10:20]')\n",
    "# dataset = load_dataset(data_name, cache_dir=data_path, split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb22d9b0-74db-4acb-bf9f-119042fbe5ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cae31aad51a45c5bd76805aa77fa6a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at ./pretrained_llms/Llama-3.3-70B-Instruct and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=3, torch_dtype=\"auto\", device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path,\n",
    "                                          add_eos_token=True,\n",
    "                                          cache_dir=cache_dir)\n",
    "\n",
    "# if tokenizer.pad_token_id is None:\n",
    "#     print(\"No pad token found in tokenizer, setting pad token to eos token\")\n",
    "#     tokenizer.pad_token = tokenizer.eos_token\n",
    "#     tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "#     tokenizer.padding_side = \"right\"\n",
    "\n",
    "# if model.config.pad_token_id is None:\n",
    "#     print(\"No pad token found in model, setting pad token to eos token of tokenizer\")\n",
    "#     model.config.pad_token_id = tokenizer.pad_token_id\n",
    "#     model.config.padding_side = \"right\"\n",
    "#     model.config.use_cache = False  # This can help with training stability\n",
    "#     model.resize_token_embeddings(len(tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b030998-926d-4de9-88a6-d62dfb92f1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True)   \n",
    "# apply tokenizer function on your data\n",
    "tokenized_data = dataset.map(tokenizer_function, batched=True)\n",
    "\n",
    "# train = tokenized_data['train'].select(range(10000))\n",
    "train = tokenized_data['train']\n",
    "test = tokenized_data['test']\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02d87870-e919-4841-867d-a3fc3eecd4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad token ID: 128004\n",
      "Model pad token ID: None\n"
     ]
    }
   ],
   "source": [
    "#Verify the tokenizer settings:\n",
    "print(f\"Pad token ID: {tokenizer.pad_token_id}\")\n",
    "print(f\"Model pad token ID: {model.config.pad_token_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432df975-6623-44d2-81dd-7bfe3fbd2e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the accuracy metric\n",
    "# metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "# def compute_metrics(eval_pred):\n",
    "#     logits, labels = eval_pred\n",
    "#     predictions = np.argmax(logits, axis=-1)\n",
    "#     return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e55ff2d-912d-4234-8a41-87e352532da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load accuracy metric\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    # Compute individual metrics\n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "    precision = precision_score(labels, predictions, average=\"weighted\", zero_division=0)\n",
    "    recall = recall_score(labels, predictions, average=\"weighted\")\n",
    "    f1 = f1_score(labels, predictions, average=\"weighted\")\n",
    "    \n",
    "    # Return all metrics\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a7f4d45-3056-4b08-bcc9-66ec5623b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test_trainer\",\n",
    "    learning_rate=1e-5,  # Experiment with different rates\n",
    "    # lr_scheduler_type=\"linear\",  # Add learning rate scheduling\n",
    "    # warmup_steps=100,  # Implement learning rate warmup\n",
    "    optim=\"adamw_torch\",\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=10,\n",
    "    save_strategy='steps',\n",
    "    save_steps=500,   \n",
    "    eval_strategy='steps',\n",
    "    logging_steps=250,\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=1,\n",
    "    # eval_steps=50,\n",
    "    # gradient_accumulation_steps=4,\n",
    "    per_device_train_batch_size=8, \n",
    "    per_device_eval_batch_size=8,   \n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=test,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "291f34de-d643-4434-8887-eb14e4d17e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='131' max='34360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  131/34360 00:26 < 1:57:38, 4.85 it/s, Epoch 0.04/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x14f754465550>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/p/project1/training2449/chou1/jupyter/kernels/chou1_kernel/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/p/project1/training2449/chou1/jupyter/kernels/chou1_kernel/lib/python3.11/site-packages/transformers/trainer.py:2171\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2169\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2172\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/p/project1/training2449/chou1/jupyter/kernels/chou1_kernel/lib/python3.11/site-packages/transformers/trainer.py:2531\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2524\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2525\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2527\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2528\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2529\u001b[0m )\n\u001b[1;32m   2530\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2531\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2534\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2535\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2536\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2537\u001b[0m ):\n\u001b[1;32m   2538\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2539\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/p/project1/training2449/chou1/jupyter/kernels/chou1_kernel/lib/python3.11/site-packages/transformers/trainer.py:3715\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3712\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_items_in_batch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3713\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n\u001b[0;32m-> 3715\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3717\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m/p/project1/training2449/chou1/jupyter/kernels/chou1_kernel/lib/python3.11/site-packages/accelerate/accelerator.py:2246\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2244\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2245\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2246\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/p/project1/training2449/chou1/jupyter/kernels/chou1_kernel/lib/python3.11/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/p/project1/training2449/chou1/jupyter/kernels/chou1_kernel/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/p/project1/training2449/chou1/jupyter/kernels/chou1_kernel/lib/python3.11/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08db60b8-2883-41e6-9d88-85106267159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_path = os.path.join(\"./saved_model\", model_name)\n",
    "trainer.save_model(save_model_path)\n",
    "print(f\"Fine-tuned model saved to: {save_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222aab2c-2828-464d-a8e9-1b04103f17ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics(metrics, model_name, data_name, base_dir=\"./results\"):\n",
    "    \"\"\"\n",
    "    Save metrics to JSON file with automatic filename generation and collision handling.\n",
    "    \"\"\"\n",
    "    # Create results directory if it doesn't exist\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "    \n",
    "    # Create base filename\n",
    "    dataset_prefix = data_name.split('/')[-1][:5]\n",
    "    base_filename = f\"fine-tuned_{model_name}_{dataset_prefix}_metrics\"\n",
    "    \n",
    "    # Generate filename with collision handling\n",
    "    filename = f\"{base_filename}.json\"\n",
    "    filepath = os.path.join(base_dir, filename)\n",
    "    \n",
    "    if os.path.exists(filepath):\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = f\"{base_filename}_{timestamp}.json\"\n",
    "        filepath = os.path.join(base_dir, filename)\n",
    "    \n",
    "    # Save to JSON\n",
    "    with open(filepath, 'w') as f:\n",
    "        json.dump(metrics, f, indent=4)\n",
    "    print(f\"Metrics saved to: {filepath}\")\n",
    "    \n",
    "    return filepath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac738953-df54-46b5-bf34-f0e1e986426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.evaluate(eval_dataset=train) #evaluate train dataset\n",
    "eval_metrics = trainer.evaluate(eval_dataset=test) #evaluate test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f29b53-8639-4025-92e8-5db7578c9a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_metrics(eval_metrics, model_name, data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2b15c1-b66a-406d-9350-e2789b69bed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(test)\n",
    "print(predictions.predictions.shape, predictions.label_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb21be7-e819-49ab-be4c-aea4916b4e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir=\"test_trainer\",\n",
    "                                  learning_rate=1e-5,  # Experiment with different rates\n",
    "                                  # lr_scheduler_type=\"linear\",  # Add learning rate scheduling\n",
    "                                  # warmup_steps=100,  # Implement learning rate warmup\n",
    "                                  optim=\"adamw_torch\",\n",
    "                                  # weight_decay=0.01,                                  \n",
    "                                  num_train_epochs=5,                                  \n",
    "                                  eval_strategy=\"epoch\",\n",
    "                                  # eval_steps=50,\n",
    "                                  # gradient_accumulation_steps=4,\n",
    "                                 )\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=test,\n",
    "    data_collator=data_collator,     \n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3439c3-f641-4e3a-b79c-15e312772b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c9e69c-d0f0-4191-9568-c0aec16faccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 3\n",
    "print(predictions.label_ids[id])\n",
    "print(train['label'][id])\n",
    "print(train['text'][id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe64bb5-08ad-4250-a9b8-f1f473013adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(task=\"sentiment-analysis\", model=model, tokenizer=tokenizer, device_map=\"auto\", padding=True, truncation=True, max_length=256)\n",
    "for out in classifier(KeyDataset(train, \"text\"), batch_size=8):\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995b1e48-9bc5-432f-8fa4-334f42e1e1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training arguments: https://huggingface.co/docs/transformers/v4.40.2/en/main_classes/trainer#transformers.TrainingArguments\n",
    "# set per_device_train_batch_size  per_device_eval_batch_size as 8,\n",
    "# we will fine tune gpt model for 30 epochs , set the corresponding parameter\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test_trainer\",\n",
    "    #evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,  \n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=30, \n",
    "    save_total_limit=2    \n",
    "    #gradient_accumulation_steps=4\n",
    "    )\n",
    "\n",
    "# set the data_collator and training arguments we defined above\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=test,\n",
    "    data_collator=data_collator, \n",
    "    compute_metrics=compute_metrics,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed348ea-0782-4b8c-a87e-2f8603a10123",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.config.num_labels)  # Confirm matches actual label count\n",
    "print(len(np.unique(train['label'])))  # Check actual unique label count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514fe7e2-ffa6-4173-b034-8732878e3ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train[0].keys())  # Verify label column exists\n",
    "print(train[1]['input_ids'])  # Confirm label format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81715262-ed50-4bb6-abd5-a080f708ca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "## When training a transformer model,\n",
    "# it’s common to batch sequences together for more efficient processing.\n",
    "# However, since sequences might have different lengths, they need to be padded to a common length within each batch.\n",
    "#The DataCollatorWithPadding class automates this process. \n",
    "\n",
    "#define the collator, use DataCollatorWithPadding() with the defined tokenizer above\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "config = GPT2Config()\n",
    "\n",
    "#define GPT classifier, use 'gpt2' pretrained LLM, we have 3 classes in our dataset \n",
    "\n",
    "model = GPT2ForSequenceClassification.from_pretrained(\"gpt2\", num_labels=3)\n",
    "model.config.pad_token_id = model.config.eos_token_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c37341d-810c-40aa-89cc-88ac84b78b40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier = pipeline(task=\"sentiment-analysis\", model=model, tokenizer=tokenizer, device=device, padding=True, truncation=True, max_length=256)\n",
    "for out in classifier(KeyDataset(dataset, \"text\"), batch_size=8):\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e0462c-d13c-4212-a63b-aa3e43751aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = classifier.tokenizer([\"Example text\", \"I am a boy\"], padding=True, truncation=True)\n",
    "print(tokens)\n",
    "print(classifier.tokenizer.pad_token)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chou1_kernel",
   "language": "python",
   "name": "chou1_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
