{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd97d42e-3d03-45d2-9bfd-76752c6712a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import pipeline\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, TrainingArguments, Trainer\n",
    "from datetime import datetime\n",
    "# import torch\n",
    "import json\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15cdfb5a-a159-4548-909f-522fa467a741",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Llama-3.1-8B-Instruct\"\n",
    "# model_name = \"Llama-3.3-70B-Instruct\"\n",
    "\n",
    "model_path = os.path.join(\"./pretrained_llms\", model_name)\n",
    "data_path = \"./data\"\n",
    "data_name = \"mteb/tweet_sentiment_extraction\"\n",
    "cache_dir = \"./cache\"\n",
    "output_dir=\"./results\"\n",
    "\n",
    "dataset = load_dataset(data_name, cache_dir=data_path)\n",
    "# dataset = load_dataset(data_name, cache_dir=data_path, split='train[10:20]')\n",
    "# dataset = load_dataset(data_name, cache_dir=data_path, split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb22d9b0-74db-4acb-bf9f-119042fbe5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=3, torch_dtype=\"auto\", device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path,\n",
    "                                          add_eos_token=True,\n",
    "                                          cache_dir=cache_dir)\n",
    "\n",
    "if tokenizer.pad_token_id is None:\n",
    "    print(\"No pad token found in tokenizer, setting pad token to eos token\")\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    tokenizer.padding_side = \"right\"\n",
    "\n",
    "if model.config.pad_token_id is None:\n",
    "    print(\"No pad token found in model, setting pad token to eos token of tokenizer\")\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    model.config.padding_side = \"right\"\n",
    "    model.config.use_cache = False  # This can help with training stability\n",
    "    model.resize_token_embeddings(len(tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b030998-926d-4de9-88a6-d62dfb92f1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True)   \n",
    "# apply tokenizer function on your data\n",
    "tokenized_data = dataset.map(tokenizer_function, batched=True)\n",
    "\n",
    "# train = tokenized_data['train'].select(range(10000))\n",
    "train = tokenized_data['train']\n",
    "test = tokenized_data['test']\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d87870-e919-4841-867d-a3fc3eecd4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verify the tokenizer settings:\n",
    "print(f\"Pad token ID: {tokenizer.pad_token_id}\")\n",
    "print(f\"Model pad token ID: {model.config.pad_token_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432df975-6623-44d2-81dd-7bfe3fbd2e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the accuracy metric\n",
    "# metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "# def compute_metrics(eval_pred):\n",
    "#     logits, labels = eval_pred\n",
    "#     predictions = np.argmax(logits, axis=-1)\n",
    "#     return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e55ff2d-912d-4234-8a41-87e352532da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load accuracy metric\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    # Compute individual metrics\n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "    precision = precision_score(labels, predictions, average=\"weighted\", zero_division=0)\n",
    "    recall = recall_score(labels, predictions, average=\"weighted\")\n",
    "    f1 = f1_score(labels, predictions, average=\"weighted\")\n",
    "    \n",
    "    # Return all metrics\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7f4d45-3056-4b08-bcc9-66ec5623b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test_trainer\",\n",
    "    learning_rate=1e-5,  # Experiment with different rates\n",
    "    # lr_scheduler_type=\"linear\",  # Add learning rate scheduling\n",
    "    # warmup_steps=100,  # Implement learning rate warmup\n",
    "    optim=\"adamw_torch\",\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=10,\n",
    "    save_strategy='steps',\n",
    "    save_steps=500,   \n",
    "    eval_strategy='steps',\n",
    "    logging_steps=250,\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=1,\n",
    "    # eval_steps=50,\n",
    "    # gradient_accumulation_steps=4,\n",
    "    per_device_train_batch_size=8, \n",
    "    per_device_eval_batch_size=8,   \n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=test,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291f34de-d643-4434-8887-eb14e4d17e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08db60b8-2883-41e6-9d88-85106267159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_path = os.path.join(\"./saved_model\", model_name)\n",
    "trainer.save_model(save_model_path)\n",
    "tokenizer.save_pretrained(save_model_path)\n",
    "print(f\"Fine-tuned model saved to: {save_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac738953-df54-46b5-bf34-f0e1e986426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.evaluate(eval_dataset=train) #evaluate train dataset\n",
    "eval_metrics = trainer.evaluate(eval_dataset=test) #evaluate test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5381988-ef01-41f7-9f86-26e47212b041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf28f785b7840d2b30356f29a9a39f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "Can't load tokenizer for './saved_model/Llama-3.1-8B-Instruct'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure './saved_model/Llama-3.1-8B-Instruct' is the correct path to a directory containing all relevant files for a LlamaTokenizerFast tokenizer.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# load saved model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./saved_model/Llama-3.1-8B-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m      5\u001b[0m     torch_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 8\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./saved_model/Llama-3.1-8B-Instruct\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_eos_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/p/project1/training2449/chou1/jupyter/kernels/chou1_kernel/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:953\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m tokenizer_class_py, tokenizer_class_fast \u001b[38;5;241m=\u001b[39m TOKENIZER_MAPPING[\u001b[38;5;28mtype\u001b[39m(config)]\n\u001b[1;32m    952\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class_fast \u001b[38;5;129;01mand\u001b[39;00m (use_fast \u001b[38;5;129;01mor\u001b[39;00m tokenizer_class_py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 953\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer_class_fast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    955\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class_py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/p/project1/training2449/chou1/jupyter/kernels/chou1_kernel/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2020\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2017\u001b[0m \u001b[38;5;66;03m# If one passes a GGUF file path to `gguf_file` there is no need for this check as the tokenizer will be\u001b[39;00m\n\u001b[1;32m   2018\u001b[0m \u001b[38;5;66;03m# loaded directly from the GGUF file.\u001b[39;00m\n\u001b[1;32m   2019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(full_file_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m full_file_name \u001b[38;5;129;01min\u001b[39;00m resolved_vocab_files\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m gguf_file:\n\u001b[0;32m-> 2020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m   2021\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load tokenizer for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. If you were trying to load it from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2022\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, make sure you don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have a local directory with the same name. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2023\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOtherwise, make sure \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is the correct path to a directory \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2024\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontaining all relevant files for a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tokenizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2025\u001b[0m     )\n\u001b[1;32m   2027\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_id, file_path \u001b[38;5;129;01min\u001b[39;00m vocab_files\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   2028\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m resolved_vocab_files:\n",
      "\u001b[0;31mOSError\u001b[0m: Can't load tokenizer for './saved_model/Llama-3.1-8B-Instruct'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure './saved_model/Llama-3.1-8B-Instruct' is the correct path to a directory containing all relevant files for a LlamaTokenizerFast tokenizer."
     ]
    }
   ],
   "source": [
    "# load saved model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"./saved_model/Llama-3.1-8B-Instruct\",\n",
    "    num_labels=3,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"./saved_model/Llama-3.1-8B-Instruct\", add_eos_token=True, cache_dir=cache_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222aab2c-2828-464d-a8e9-1b04103f17ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics(metrics, model_name, data_name, base_dir=\"./results\"):\n",
    "    \"\"\"\n",
    "    Save metrics to JSON file with automatic filename generation and collision handling.\n",
    "    \"\"\"\n",
    "    # Create results directory if it doesn't exist\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "    \n",
    "    # Create base filename\n",
    "    dataset_prefix = data_name.split('/')[-1][:5]\n",
    "    base_filename = f\"fine-tuned_{model_name}_{dataset_prefix}_metrics\"\n",
    "    \n",
    "    # Generate filename with collision handling\n",
    "    filename = f\"{base_filename}.json\"\n",
    "    filepath = os.path.join(base_dir, filename)\n",
    "    \n",
    "    if os.path.exists(filepath):\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = f\"{base_filename}_{timestamp}.json\"\n",
    "        filepath = os.path.join(base_dir, filename)\n",
    "    \n",
    "    # Save to JSON\n",
    "    with open(filepath, 'w') as f:\n",
    "        json.dump(metrics, f, indent=4)\n",
    "    print(f\"Metrics saved to: {filepath}\")\n",
    "    \n",
    "    return filepath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f29b53-8639-4025-92e8-5db7578c9a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_metrics(eval_metrics, model_name, data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2b15c1-b66a-406d-9350-e2789b69bed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(test)\n",
    "print(predictions.predictions.shape, predictions.label_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb21be7-e819-49ab-be4c-aea4916b4e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test_trainer\",\n",
    "    learning_rate=1e-5,  # Experiment with different rates\n",
    "    # lr_scheduler_type=\"linear\",  # Add learning rate scheduling\n",
    "    # warmup_steps=100,  # Implement learning rate warmup\n",
    "    optim=\"adamw_torch\",\n",
    "    # weight_decay=0.01,\n",
    "    num_train_epochs=5,\n",
    "    eval_strategy=\"epoch\",\n",
    "    # eval_steps=50,\n",
    "    # gradient_accumulation_steps=4,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=test,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3439c3-f641-4e3a-b79c-15e312772b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98c9e69c-d0f0-4191-9568-c0aec16faccf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpredictions\u001b[49m\u001b[38;5;241m.\u001b[39mlabel_ids[\u001b[38;5;28mid\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;28mid\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;28mid\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "id = 3\n",
    "print(predictions.label_ids[id])\n",
    "print(train['label'][id])\n",
    "print(train['text'][id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe64bb5-08ad-4250-a9b8-f1f473013adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(task=\"sentiment-analysis\", model=model, tokenizer=tokenizer, device_map=\"auto\", padding=True, truncation=True, max_length=256)\n",
    "for out in classifier(KeyDataset(train, \"text\"), batch_size=8):\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995b1e48-9bc5-432f-8fa4-334f42e1e1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training arguments: https://huggingface.co/docs/transformers/v4.40.2/en/main_classes/trainer#transformers.TrainingArguments\n",
    "# set per_device_train_batch_size  per_device_eval_batch_size as 8,\n",
    "# we will fine tune gpt model for 30 epochs , set the corresponding parameter\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test_trainer\",\n",
    "    #evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,  \n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=30, \n",
    "    save_total_limit=2    \n",
    "    #gradient_accumulation_steps=4\n",
    "    )\n",
    "\n",
    "# set the data_collator and training arguments we defined above\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=test,\n",
    "    data_collator=data_collator, \n",
    "    compute_metrics=compute_metrics,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c37341d-810c-40aa-89cc-88ac84b78b40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier = pipeline(task=\"sentiment-analysis\", model=model, tokenizer=tokenizer, device=device, padding=True, truncation=True, max_length=256)\n",
    "for out in classifier(KeyDataset(dataset, \"text\"), batch_size=8):\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed348ea-0782-4b8c-a87e-2f8603a10123",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.config.num_labels)  # Confirm matches actual label count\n",
    "print(len(np.unique(train['label'])))  # Check actual unique label count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514fe7e2-ffa6-4173-b034-8732878e3ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train[0].keys())  # Verify label column exists\n",
    "print(train[1]['input_ids'])  # Confirm label format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81715262-ed50-4bb6-abd5-a080f708ca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "## When training a transformer model,\n",
    "# it’s common to batch sequences together for more efficient processing.\n",
    "# However, since sequences might have different lengths, they need to be padded to a common length within each batch.\n",
    "#The DataCollatorWithPadding class automates this process. \n",
    "\n",
    "#define the collator, use DataCollatorWithPadding() with the defined tokenizer above\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "config = GPT2Config()\n",
    "\n",
    "#define GPT classifier, use 'gpt2' pretrained LLM, we have 3 classes in our dataset \n",
    "\n",
    "model = GPT2ForSequenceClassification.from_pretrained(\"gpt2\", num_labels=3)\n",
    "model.config.pad_token_id = model.config.eos_token_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e0462c-d13c-4212-a63b-aa3e43751aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = classifier.tokenizer([\"Example text\", \"I am a boy\"], padding=True, truncation=True)\n",
    "print(tokens)\n",
    "print(classifier.tokenizer.pad_token)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chou1_kernel",
   "language": "python",
   "name": "chou1_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
